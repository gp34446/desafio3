{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitdesa3conda440b38fca8bd413a9329e34e19d35085",
   "display_name": "Python 3.7.6 64-bit ('desa3': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En este paso, levantamos el nuevo dataset y aplicamos transformaciones, one hot enconder para las columnas categoricas y scalar para las numericas. Al terminar las transformaciones aplicamos RFE para eliminar features, el resultado de este paso se guarda como matriz esparsa en un file.\n",
    "En el siguiente paso se debera levantar la X y Y de files como se indica a continaucion:\n",
    "\n",
    "y = pd.read_csv('../desafio3/datasets/df_final.csv', parse_dates=True, na_values=['nc'], low_memory=False)\n",
    "y = y['nivel_desemp_matematica']\n",
    "X = scipy.sparse.load_npz('../desafio3/datasets/sparse.npz')\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "import scipy.sparse\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "df = pd.read_csv('../desafio3/datasets/df_final.csv', parse_dates=True, na_values=['nc'], low_memory=False)\n",
    "\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "for i in df.columns:\n",
    "    if (df[i].dtype == object) or i in ['nivel_id', 'escuela_id', 'provincia_id', 'departamento_id']:\n",
    "        df[i] = pd.Categorical(df[i])\n",
    "\n",
    "X = df.drop('nivel_desemp_matematica', axis=1)\n",
    "y = df['nivel_desemp_matematica']\n",
    "folds=StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns = 'n'):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            #c para tomar columnas categoricas, cualquier otro valor para tomar continuas.\n",
    "            if self.columns == 'c':\n",
    "                categorical_columns = [col for col in X.columns if pd.api.types.is_categorical_dtype(df[col])]\n",
    "                return pd.DataFrame(X[categorical_columns])\n",
    "            else:\n",
    "                scal_columns = [col for col in X.columns if (pd.api.types.is_categorical_dtype(df[col]) == False)]\n",
    "                return pd.DataFrame(X[scal_columns])\n",
    "        else:\n",
    "            raise TypeError(\"Este Transformador solo funciona en DF de Pandas\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "cat_pipe = make_pipeline(ColumnSelector('c'),OneHotEncoder(handle_unknown='error',drop = 'first'))\n",
    "num_pipe = make_pipeline(ColumnSelector('n'),RobustScaler())\n",
    "union = make_union(num_pipe,\n",
    "                   cat_pipe)\n",
    "            \n",
    "lr = LogisticRegression()\n",
    "rfe = RFECV(lr,step=2000, cv=folds, n_jobs=5) \n",
    "df_union = rfe.fit_transform(union.fit_transform(X), y)\n",
    "scipy.sparse.save_npz('../desafio3/datasets/sparse.npz',df_union)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(277573, 7014)\n"
    }
   ],
   "source": [
    "X = scipy.sparse.load_npz('../desafio3/datasets/sparse.npz')\n",
    "print(X.shape)\n"
   ]
  }
 ]
}