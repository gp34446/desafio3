{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitdhcondac51ae0c7bb5d4a4fb15b9da2fc882088",
   "display_name": "Python 3.7.6 64-bit ('dh': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "#######SHAPE: \n (293509, 32) \n ####### \n\n#######VALUE_COUNTS: \n 0    175988\n1    117521\nName: nivel_desemp_matematica, dtype: int64 \n ####### \n\n#######NULLs: \n sexo                               0.0\nindice_socioeconomico              0.0\nnivel_desemp_matematica            0.0\nnivel_desemp_lengua                0.0\nponderador_lengua                  0.0\nponderador_matematica              0.0\nponderador_ciencias_naturales      0.0\nponderador_ciencias_sociales       0.0\ntiene_notebook                     0.0\ntiene_pc                           0.0\ntiene_tablet                       0.0\ntiene_celular                      0.0\ntiene_smartphone                   0.0\ntiene_consola                      0.0\ntiene_smarttv                      0.0\ntiene_cable                        0.0\ntiene_internet_x                   0.0\nrepeticion_primaria                0.0\nescuela_id                         0.0\nnivel_id                           0.0\nambito                             0.0\ngestion                            0.0\nicse                               0.0\nindice_socioeconomico_medio        0.0\nindice_socioeconomico_medio_cat    0.0\ntecnica                            0.0\ntiene_internet_y                   0.0\nsubvencion                         0.0\ndependencia                        0.0\ndepartamento_id                    0.0\nprovincia_id                       0.0\nmatricula                          0.0\ndtype: float64 \n ####### \n\n#######BALANCE: \n 0    175988\n1    117521\nName: nivel_desemp_matematica, dtype: int64 \n ####### \n\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "En este paso filtramos el dataset de alumnos por el año 2016 y hacemos join con el dataset de escuelas.\n",
    "Luego eliminamos NULLs y grabamos el file df_final.csv. Pensando en predecir el campo nivel_desemp_matematica, \n",
    "lo transofrmamos en dos categorias, SATIFACTORIO con valor 0 (satifactorio y avanzado) y 1 BÁSICO (básico y por debajo de básico).\n",
    "Para ejecutar este paso deben tener en la carpeta /desafio3/datasets , los datasets app_alumno.csv y app_escuela.csv.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../desafio3/datasets/app_alumno.csv', parse_dates=True, na_values=['nc'], low_memory=False)\n",
    "df_escuelas = pd.read_csv('../desafio3/datasets/app_escuela.csv', parse_dates=True, na_values=['nc'], low_memory=False)\n",
    "df = df[(df['nivel_desemp_matematica'].notnull()) & (df['year_id'] == 2016)]\n",
    "df = df.drop(['id','repeticion_secundaria','nivel_desemp_ciencias_sociales','nivel_desemp_ciencias_naturales','year_id'], axis=1)\n",
    "df = df.dropna(axis=0)\n",
    "df['nivel_desemp_matematica'] = df['nivel_desemp_matematica'].apply(lambda x: 0 if x in ['satisfactorio','avanzado'] else 1)\n",
    "\n",
    "#### SE AGREGA JOIN PARA AGREGAR AL DATAFRAME LA CANTIDAD DE ALUMNOS QUE TIENE CADA ESCUELA\n",
    "df_curso = pd.read_csv('../desafio3/datasets/app_curso.csv', parse_dates=True, na_values=['nc'], low_memory=False)\n",
    "df_curso = df_curso[df_curso['year_id'] == 2016]\n",
    "df_curso_gr = df_curso.groupby(by='escuela_id')['matricula'].sum()\n",
    "df_curso_gr = df_curso_gr.reset_index()\n",
    "df_escuelas = df_escuelas.rename(columns={'id': 'escuela_id'})\n",
    "df_escuelas = df_escuelas.merge(df_curso_gr, how='inner', on ='escuela_id')\n",
    "####\n",
    "\n",
    "df = df.merge(df_escuelas, how='inner', on ='escuela_id')\n",
    "df = df.drop('icse_cat', axis=1)\n",
    "df = df.dropna(axis=0)\n",
    "print('#######SHAPE:','\\n',df.shape,'\\n','#######','\\n')\n",
    "print('#######VALUE_COUNTS:','\\n',df['nivel_desemp_matematica'].value_counts(),'\\n','#######','\\n')\n",
    "print('#######NULLs:','\\n',(df.isnull().sum()/df.shape[0])*100,'\\n','#######','\\n')\n",
    "print('#######BALANCE:','\\n',df['nivel_desemp_matematica'].value_counts(),'\\n','#######','\\n')\n",
    "df.to_csv('../desafio3/datasets/df_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En este paso, levantamos el nuevo dataset y convertimos al tipo de dato category las columnas que consideramos categoricas\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('../desafio3/datasets/df_final.csv', parse_dates=True, na_values=['nc'], low_memory=False)\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "for i in df.columns:\n",
    "    if (df[i].dtype == object) or i in ['nivel_id', 'escuela_id', 'provincia_id', 'departamento_id']:\n",
    "        df[i] = pd.Categorical(df[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"A continuación ejecutamos modelos de regresión logistica para validar que el dataset final sea adecuado para trabajar .\n",
    "\"\"\"\n",
    "X = df.drop('nivel_desemp_matematica', axis=1)\n",
    "y = df['nivel_desemp_matematica']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns = 'n'):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def transform(self, X, *_):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            #c para tomar columnas categoricas, cualquier otro valor para tomar continuas.\n",
    "            if self.columns == 'c':\n",
    "                categorical_columns = [col for col in X.columns if pd.api.types.is_categorical_dtype(df[col])]\n",
    "                return pd.DataFrame(X[categorical_columns])\n",
    "            else:\n",
    "                scal_columns = [col for col in X.columns if (pd.api.types.is_categorical_dtype(df[col]) == False)]\n",
    "                return pd.DataFrame(X[scal_columns])\n",
    "        else:\n",
    "            raise TypeError(\"Este Transformador solo funciona en DF de Pandas\")\n",
    "    \n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "cat_pipe = make_pipeline(ColumnSelector('c'),OneHotEncoder(handle_unknown='ignore'))\n",
    "num_pipe = make_pipeline(ColumnSelector('n'),StandardScaler())\n",
    "union = make_union(num_pipe,\n",
    "                   cat_pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best score: 0.739\nBest parameters set:\n\t log__C: 0.1\n\t log__penalty: 'l2'\n              precision    recall  f1-score   support\n\n           0       0.77      0.81      0.79     44028\n           1       0.69      0.63      0.66     29395\n\n    accuracy                           0.74     73423\n   macro avg       0.73      0.72      0.72     73423\nweighted avg       0.73      0.74      0.74     73423\n\n0.7373302643585797\n"
    }
   ],
   "source": [
    "#Este paso tarda bastante dado que ejecutamos un random grid search.\n",
    "\"\"\"\n",
    "RESULTADO: \n",
    "Best score: 0.739\n",
    "Best parameters set:\n",
    "\t log__C: 0.1\n",
    "\t log__penalty: 'l2'\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.77      0.81      0.79     44028\n",
    "           1       0.69      0.63      0.66     29395\n",
    "\n",
    "    accuracy                           0.74     73423\n",
    "   macro avg       0.73      0.72      0.72     73423\n",
    "weighted avg       0.73      0.74      0.74     73423\n",
    "\n",
    "0.7373302643585797\n",
    "\"\"\"\n",
    "union.fit_transform(X)\n",
    "\n",
    "pipeline = Pipeline([('union', union), \n",
    "                     ('log', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "parameters = {'log__penalty': ['l1', 'l2'],\n",
    "              'log__C': [0.01, 0.1, 1, 10, 100]}\n",
    "folds=StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "grid_search = RandomizedSearchCV(pipeline, parameters,cv=folds, n_jobs = 5)\n",
    "grid_search.fit(pd.DataFrame(X_train, columns=X.columns), y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_) \n",
    "print(\"Best parameters set:\" )\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted (parameters . keys()): \n",
    "                    print(\"\\t %s: %r\" % (param_name, best_parameters[param_name])) \n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ]
}